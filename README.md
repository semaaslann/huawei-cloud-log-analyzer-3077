# Huawei Cloud Log Analysis Pipeline

## Description

This project implements a log analysis pipeline on Huawei Cloud. It ingests logs from various sources, stores them in OBS, processes them using MRS (Spark), and visualizes anomalies and key metrics in Grafana.

## Architecture

The architecture is as follows:

*   **Application/Service Logs:** Logs generated by various applications and services.
*   **Log Service (LTS):** Huawei Cloud's managed log collection and ingestion service. Ingests logs from various sources.
*   **Object Storage Service (OBS):** Huawei Cloud's object storage service. Stores the ingested logs.
*   **MapReduce Service (MRS) - Spark:** Huawei Cloud's big data processing service, using Spark to process logs.
*   **Anomaly Detection & Aggregation:** Spark jobs analyze the logs and detect anomalies, and aggregate useful metrics.
*   **Grafana:** Open-source data visualization and monitoring tool. Visualizes the processed data and anomalies.
*   **User Dashboard:** A web-based dashboard for users to view the log analysis results.

## Setup

1.  Install Docker and Docker Compose.
2.  Clone this repository.
3.  Configure Grafana to connect to the Spark processed data (this part requires manual configuration on Huawei Cloud MRS to export data to a format Grafana can read, e.g., a database).
4.  Run `docker-compose up -d` to start Grafana and the Spark History Server.
5.  Access Grafana at `http://localhost:3000` with default credentials `admin/admin`.
6. Access Spark History Server at `http://localhost:18080`

## Huawei Cloud Setup (Important)

1. Configure LTS to ingest logs from your applications and services.
2. Configure LTS to store the ingested logs in OBS.
3. Create an MRS cluster with Spark.
4. Develop Spark jobs to read logs from OBS, process them, perform anomaly detection, and aggregate metrics.
5. Ensure the Spark jobs output the processed data to a datastore (e.g., a database) that Grafana can access.
6. Configure Grafana to connect to the datastore and create dashboards to visualize the data.
